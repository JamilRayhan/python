{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf7e7e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:07.999104Z",
     "start_time": "2023-11-29T05:06:07.990682Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad5f6a50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:08.371018Z",
     "start_time": "2023-11-29T05:06:08.002119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 6)\n",
      "Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
      "       'Species'],\n",
      "      dtype='object')\n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "5   6            5.4           3.9            1.7           0.4  Iris-setosa\n",
      "6   7            4.6           3.4            1.4           0.3  Iris-setosa\n",
      "7   8            5.0           3.4            1.5           0.2  Iris-setosa\n",
      "8   9            4.4           2.9            1.4           0.2  Iris-setosa\n",
      "9  10            4.9           3.1            1.5           0.1  Iris-setosa\n",
      "               Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "count  150.000000     150.000000    150.000000     150.000000    150.000000\n",
      "mean    75.500000       5.843333      3.054000       3.758667      1.198667\n",
      "std     43.445368       0.828066      0.433594       1.764420      0.763161\n",
      "min      1.000000       4.300000      2.000000       1.000000      0.100000\n",
      "25%     38.250000       5.100000      2.800000       1.600000      0.300000\n",
      "50%     75.500000       5.800000      3.000000       4.350000      1.300000\n",
      "75%    112.750000       6.400000      3.300000       5.100000      1.800000\n",
      "max    150.000000       7.900000      4.400000       6.900000      2.500000\n"
     ]
    }
   ],
   "source": [
    "iris_data = pd.read_csv('Iris.csv')\n",
    "\n",
    "# dimensions (no. of rows & columns)\n",
    "print(iris_data.shape)\n",
    "# list of columns/features\n",
    "print(iris_data.columns) \n",
    "# peek some data\n",
    "print(iris_data.head(10))\n",
    "# statistical summary\n",
    "print(iris_data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c4e0236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:08.731725Z",
     "start_time": "2023-11-29T05:06:08.374109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: count, dtype: int64\n",
      "Species\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# target variable\n",
    "target = iris_data['Species']\n",
    "# distribution of class labels or categories\n",
    "print(pd.value_counts(target))\n",
    "# alternative of finding class distribution\n",
    "print(iris_data.groupby('Species').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "10f57f95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:08.899059Z",
     "start_time": "2023-11-29T05:06:08.737742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of training data : (105, 6)\n",
      "\n",
      "Shape of testing data : (45, 6)\n",
      "Species\n",
      "Iris-versicolor    35\n",
      "Iris-setosa        35\n",
      "Iris-virginica     35\n",
      "Name: count, dtype: int64\n",
      "Species\n",
      "Iris-versicolor    15\n",
      "Iris-virginica     15\n",
      "Iris-setosa        15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "train_data, test_data = train_test_split(iris_data, test_size=0.3, random_state=seed, stratify=target)\n",
    "# shape of the datasets\n",
    "print('\\nShape of training data :',train_data.shape)\n",
    "print('\\nShape of testing data :',test_data.shape)\n",
    "# class distribution of the training data\n",
    "print(pd.value_counts(train_data['Species']))\n",
    "# class distribution of the test data\n",
    "print(pd.value_counts(test_data['Species']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "df8dcf52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:08.986416Z",
     "start_time": "2023-11-29T05:06:08.903070Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# separate the independent and target variables from training data\n",
    "train_x = train_data.drop(columns=['Species'],axis=1)\n",
    "train_y = train_data['Species']\n",
    "# separate the independent and target variables from test data\n",
    "test_x = test_data.drop(columns=['Species'],axis=1)\n",
    "test_y = test_data['Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c684ba1",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ecb2749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:09.125217Z",
     "start_time": "2023-11-29T05:06:08.989023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy (Decision Tree): 1.0\n",
      "Test Accuracy (Decision Tree): 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# create a classifier object/model \n",
    "model = tree.DecisionTreeClassifier()\n",
    "# train the model with fit function\n",
    "model.fit(train_x, train_y)\n",
    "# make predictions on training data\n",
    "predictions_train = model.predict(train_x)\n",
    "print('\\nTraining Accuracy (Decision Tree):', accuracy_score(train_y, predictions_train))\n",
    "# make predictions on test data\n",
    "predictions_test = model.predict(test_x)\n",
    "print('Test Accuracy (Decision Tree):', accuracy_score(test_y, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e24de",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6418a7c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:09.287524Z",
     "start_time": "2023-11-29T05:06:09.128228Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy (Logistic Regression): 1.0\n",
      "Test Accuracy (Logistic Regression): 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# create a classifier object/model \n",
    "model = LogisticRegression(max_iter=1000)\n",
    "# train the model with fit function\n",
    "model.fit(train_x , train_y)\n",
    "# make predictions on training data\n",
    "predictions_train = model.predict(train_x)\n",
    "print('\\nTraining Accuracy (Logistic Regression):', accuracy_score(train_y, predictions_train))\n",
    "# make predictions on test data\n",
    "predictions_test = model.predict(test_x)\n",
    "print('Test Accuracy (Logistic Regression):', accuracy_score(test_y, predictions_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b164aae7",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "989b279a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:09.377226Z",
     "start_time": "2023-11-29T05:06:09.289934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy (K-Nearest Neighbors): 1.0\n",
      "Test Accuracy (K-Nearest Neighbors): 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# create a classifier object/model \n",
    "model = KNeighborsClassifier()\n",
    "# train the model with fit function\n",
    "model.fit(train_x, train_y)\n",
    "# make predictions on training data\n",
    "predictions_train = model.predict(train_x)\n",
    "print('\\nTraining Accuracy (K-Nearest Neighbors):', accuracy_score(train_y, predictions_train))\n",
    "# make predictions on test data\n",
    "predictions_test = model.predict(test_x)\n",
    "print('Test Accuracy (K-Nearest Neighbors):', accuracy_score(test_y, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53985b",
   "metadata": {},
   "source": [
    "# normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58d5b9e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:09.500502Z",
     "start_time": "2023-11-29T05:06:09.378276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the scaler on the training data\n",
    "train_x_scaled = scaler.fit_transform(train_x)\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "test_x_scaled = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e9f08c",
   "metadata": {},
   "source": [
    "# After normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d9df170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:09.612277Z",
     "start_time": "2023-11-29T05:06:09.508489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Classifier  Training Accuracy  Test Accuracy\n",
      "0  Decision Tree                 1.0       0.955556\n"
     ]
    }
   ],
   "source": [
    "# Initialize results DataFrame outside the loop\n",
    "results_df = pd.DataFrame(columns=['Classifier', 'Training Accuracy', 'Test Accuracy'])\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "# train the model with fit function\n",
    "model.fit(train_x_scaled, train_y)\n",
    "# make predictions on training data\n",
    "predictions_train = model.predict(train_x_scaled)\n",
    "#print('\\nTraining Accuracy (Decision Tree - with normalization):', accuracy_score(train_y, predictions_train))\n",
    "# make predictions on test data\n",
    "predictions_test = model.predict(test_x_scaled)\n",
    "#print('Test Accuracy (Decision Tree - with normalization):', accuracy_score(test_y, predictions_test))\n",
    "new_results_df = pd.DataFrame({\n",
    "    'Classifier': ['Decision Tree '],\n",
    "    'Training Accuracy': [accuracy_score(train_y, predictions_train)],\n",
    "    'Test Accuracy': [accuracy_score(test_y, predictions_test)]\n",
    "})\n",
    "\n",
    "# Concatenate results to the existing DataFrame\n",
    "results_df = pd.concat([results_df, new_results_df], ignore_index=True)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeffc4fe",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4b4dc715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:09.761723Z",
     "start_time": "2023-11-29T05:06:09.612277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Classifier  Training Accuracy  Test Accuracy\n",
      "0       Decision Tree            1.000000       0.955556\n",
      "1  Logistic Regression           0.990476       0.977778\n"
     ]
    }
   ],
   "source": [
    "# create a classifier object/model \n",
    "model = LogisticRegression()\n",
    "# train the model with fit function\n",
    "model.fit(train_x_scaled, train_y)\n",
    "# make predictions on training data\n",
    "predictions_train = model.predict(train_x_scaled)\n",
    "#print('\\nTraining Accuracy (Logistic Regression - with normalization):', accuracy_score(train_y, predictions_train))\n",
    "# make predictions on test data\n",
    "predictions_test = model.predict(test_x_scaled)\n",
    "#print('Test Accuracy (Logistic Regression - with normalization):', accuracy_score(test_y, predictions_test))\n",
    "# Create a DataFrame for results\n",
    "new_results_df = pd.DataFrame({\n",
    "    'Classifier': ['Logistic Regression'],\n",
    "    'Training Accuracy': [accuracy_score(train_y, predictions_train)],\n",
    "    'Test Accuracy': [accuracy_score(test_y, predictions_test)]\n",
    "})\n",
    "\n",
    "# Concatenate results to the existing DataFrame\n",
    "results_df = pd.concat([results_df, new_results_df], ignore_index=True)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31df82b",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f8b067b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T05:06:09.875637Z",
     "start_time": "2023-11-29T05:06:09.761723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Classifier  Training Accuracy  Test Accuracy\n",
      "0       Decision Tree            1.000000       0.955556\n",
      "1  Logistic Regression           0.990476       0.977778\n",
      "2  K-Nearest Neighbors           1.000000       0.977778\n"
     ]
    }
   ],
   "source": [
    "# create a classifier object/model \n",
    "model = KNeighborsClassifier()\n",
    "# train the model with fit function\n",
    "model.fit(train_x_scaled, train_y)\n",
    "# make predictions on training data\n",
    "predictions_train = model.predict(train_x_scaled)\n",
    "#print('\\nTraining Accuracy (K-Nearest Neighbors - with normalization):', accuracy_score(train_y, predictions_train))\n",
    "# make predictions on test data\n",
    "predictions_test = model.predict(test_x_scaled)\n",
    "#print('Test Accuracy (K-Nearest Neighbors - with normalization):', accuracy_score(test_y, predictions_test))\n",
    "\n",
    "# Create a DataFrame for results\n",
    "new_results_df = pd.DataFrame({\n",
    "    'Classifier': ['K-Nearest Neighbors'],\n",
    "    'Training Accuracy': [accuracy_score(train_y, predictions_train)],\n",
    "    'Test Accuracy': [accuracy_score(test_y, predictions_test)]\n",
    "})\n",
    "\n",
    "# Concatenate results to the existing DataFrame\n",
    "results_df = pd.concat([results_df, new_results_df], ignore_index=True)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
